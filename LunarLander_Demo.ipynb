{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lunar Lander Reinforcement Learning Demo\n",
        "\n",
        "This notebook demonstrates the Lunar Lander reinforcement learning model in both clean and robust environments.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Omerlol2004/Lunar-Lander-rl/blob/main/LunarLander_Demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment\n",
        "\n",
        "First, let's install the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gymnasium[box2d]==0.28.1 stable-baselines3==2.0.0 numpy==1.24.3 torch==2.0.1 matplotlib==3.7.2 imageio==2.31.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Model Files\n",
        "\n",
        "Download the model files from GitHub Releases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# URLs for model files\n",
        "best_model_url = 'https://github.com/Omerlol2004/Lunar-Lander-rl/releases/download/v1.1/best_model.zip'\n",
        "vecnorm_url = 'https://github.com/Omerlol2004/Lunar-Lander-rl/releases/download/v1.1/lander_vecnorm.pkl'\n",
        "\n",
        "# Download files\n",
        "def download_file(url, local_path):\n",
        "    if os.path.exists(local_path):\n",
        "        print(f'{local_path} already exists, skipping download')\n",
        "        return\n",
        "    \n",
        "    print(f'Downloading {url} to {local_path}...')\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    with open(local_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f'Downloaded {local_path}')\n",
        "\n",
        "# Download model files\n",
        "download_file(best_model_url, 'models/best_model.zip')\n",
        "download_file(vecnorm_url, 'models/lander_vecnorm.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries\n",
        "\n",
        "Import the necessary libraries for running the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import imageio\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n",
        "\n",
        "Define helper functions for running episodes and displaying results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_env(robust=False):\n",
        "    '''Create environment with optional robustness parameter'''
",
        "    if robust:\n",
        "        # Create robust environment with disturbances\n",
        "        return gym.make('LunarLander-v2', continuous=False, enable_wind=True, wind_power=15.0, turbulence_power=1.5)\n",
        "    else:\n",
        "        # Create clean environment\n",
        "        return gym.make('LunarLander-v2', continuous=False)\n",
        "\n",
        "def run_episodes(env_type='clean', num_episodes=10, render=True):\n",
        "    '''Run episodes and return rewards and frames'''
",
        "    # Create environment\n",
        "    is_robust = (env_type == 'robust')\n",
        "    \n",
        "    def make_env():\n",
        "        return lambda: create_env(robust=is_robust)\n",
        "    \n",
        "    env = DummyVecEnv([make_env()])\n",
        "    \n",
        "    # Load VecNormalize statistics\n",
        "    vec_normalize = VecNormalize.load('models/lander_vecnorm.pkl', env)\n",
        "    vec_normalize.training = False\n",
        "    vec_normalize.norm_reward = False\n",
        "    \n",
        "    # Load model\n",
        "    model = PPO.load('models/best_model.zip', env=vec_normalize)\n",
        "    \n",
        "    all_rewards = []\n",
        "    all_frames = []\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        obs = vec_normalize.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        episode_frames = []\n",
        "        \n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, info = vec_normalize.step(action)\n",
        "            episode_reward += reward[0]\n",
        "            \n",
        "            if render:\n",
        "                frame = env.render(mode='rgb_array')[0]\n",
        "                episode_frames.append(frame)\n",
        "        \n",
        "        all_rewards.append(episode_reward)\n",
        "        if render:\n",
        "            all_frames.extend(episode_frames)\n",
        "        \n",
        "        print(f'Episode {episode+1}/{num_episodes}, Reward: {episode_reward:.2f}')\n",
        "    \n",
        "    env.close()\n",
        "    return all_rewards, all_frames\n",
        "\n",
        "def display_video(frames, fps=30):\n",
        "    '''Display video of frames'''
",
        "    if not frames:\n",
        "        return HTML('No frames to display')\n",
        "    \n",
        "    video_file = io.BytesIO()\n",
        "    imageio.mimsave(video_file, frames, fps=fps, format='mp4')\n",
        "    video_file.seek(0)\n",
        "    video_base64 = b64encode(video_file.read()).decode('ascii')\n",
        "    \n",
        "    return HTML(f'''\n",
        "    <video width="640" height="480" controls>\n",
        "      <source src="data:video/mp4;base64,{video_base64}" type="video/mp4">\n",
        "    </video>\n",
        "    ''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Clean Environment\n",
        "\n",
        "Run 10 episodes in the clean environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_rewards, clean_frames = run_episodes(env_type='clean', num_episodes=10)\n",
        "\n",
        "print(f'\nClean Environment Results:\n')\n",
        "print(f'Average Reward: {np.mean(clean_rewards):.2f} ± {np.std(clean_rewards):.2f}')\n",
        "print(f'Min Reward: {np.min(clean_rewards):.2f}')\n",
        "print(f'Max Reward: {np.max(clean_rewards):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display video of clean environment\n",
        "display_video(clean_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Robust Environment\n",
        "\n",
        "Run 10 episodes in the robust environment with disturbances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "robust_rewards, robust_frames = run_episodes(env_type='robust', num_episodes=10)\n",
        "\n",
        "print(f'\nRobust Environment Results:\n')\n",
        "print(f'Average Reward: {np.mean(robust_rewards):.2f} ± {np.std(robust_rewards):.2f}')\n",
        "print(f'Min Reward: {np.min(robust_rewards):.2f}')\n",
        "print(f'Max Reward: {np.max(robust_rewards):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display video of robust environment\n",
        "display_video(robust_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Results\n",
        "\n",
        "Compare the performance in clean and robust environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot([clean_rewards, robust_rewards], labels=['Clean', 'Robust'])\n",
        "plt.title('Reward Distribution: Clean vs Robust Environment')\n",
        "plt.ylabel('Episode Reward')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add individual points\n",
        "for i, data in enumerate([clean_rewards, robust_rewards]):\n",
        "    x = np.random.normal(i+1, 0.04, size=len(data))\n",
        "    plt.scatter(x, data, alpha=0.6)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}